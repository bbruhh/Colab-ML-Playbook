{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 0-Q-Table Learning-Clean.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "EloeXg5xdYFy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img height=\"60px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"20px\" vspace=\"5px\">\n",
        "\n",
        "# Q-Table Learning"
      ]
    },
    {
      "metadata": {
        "id": "qh2udjl5dgjn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* References:\n",
        "\n",
        "[https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0](https://medium.com/emergent-future/simple-reinforcement-learning-with-tensorflow-part-0-q-learning-with-tables-and-neural-networks-d195264329d0)"
      ]
    },
    {
      "metadata": {
        "id": "rTHpmV51dq23",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/learning-stack/Colab-ML-Playbook/blob/master/Reinforcement%20Learning/Simple%20Reinforcement%20Learning%20with%20Tensorflow/Part%200-Q-Table%20Learning-Clean.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/learning-stack/Colab-ML-Playbook/blob/master/Reinforcement%20Learning/Simple%20Reinforcement%20Learning%20with%20Tensorflow/Part%200-Q-Table%20Learning-Clean.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "og93smsWdYF_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dea0db57-5987-45f4-9f77-3b7adfa4d5a0"
      },
      "cell_type": "code",
      "source": [
        "#installing dependencies\n",
        "!apt-get -qq -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1 > /dev/null\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n",
        "!pip -q install gym\n",
        "!pip -q install pyglet\n",
        "!pip -q install pyopengl\n",
        "!pip -q install pyvirtualdisplay"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting templates from packages: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PLXbqp6qe1Yo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mIJx0fREdYGS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the environment"
      ]
    },
    {
      "metadata": {
        "id": "pNNibxBAdYGV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "env = gym.make('FrozenLake-v0')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3A-FWgedYGh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Implement Q-Table learning algorithm"
      ]
    },
    {
      "metadata": {
        "id": "5rMvXnmydYGj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Initialize table with all zeros\n",
        "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
        "# Set learning parameters\n",
        "lr = .8\n",
        "y = .95\n",
        "num_episodes = 2000\n",
        "#create lists to contain total rewards and steps per episode\n",
        "#jList = []\n",
        "rList = []\n",
        "for i in range(num_episodes):\n",
        "    #Reset environment and get first new observation\n",
        "    s = env.reset()\n",
        "    rAll = 0\n",
        "    d = False\n",
        "    j = 0\n",
        "    #The Q-Table learning algorithm\n",
        "    while j < 99:\n",
        "        j+=1\n",
        "        #Choose an action by greedily (with noise) picking from Q table\n",
        "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))\n",
        "        #Get new state and reward from environment\n",
        "        s1,r,d,_ = env.step(a)\n",
        "        #Update Q-Table with new knowledge\n",
        "        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a])\n",
        "        rAll += r\n",
        "        s = s1\n",
        "        if d == True:\n",
        "            break\n",
        "    #jList.append(j)\n",
        "    rList.append(rAll)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i9y5EP3bdYGm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a522a98-8a84-41e8-daa8-3bd0486b5194"
      },
      "cell_type": "code",
      "source": [
        "print \"Score over time: \" +  str(sum(rList)/num_episodes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score over time: 0.485\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HcXE8AQ9dYHN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "a65d7a51-ba80-45fd-e131-47272bb92f92"
      },
      "cell_type": "code",
      "source": [
        "print \"Final Q-Table Values\"\n",
        "print Q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Final Q-Table Values\n",
            "[[4.19994367e-01 5.81112250e-03 5.22528105e-03 6.11735683e-03]\n",
            " [1.04662603e-03 7.21004928e-04 2.03639719e-04 8.02813506e-02]\n",
            " [9.42434195e-02 3.77313787e-03 3.41692595e-03 4.77874253e-03]\n",
            " [7.12104557e-04 3.39940614e-03 3.32210834e-03 4.74789319e-03]\n",
            " [6.16705717e-01 3.91800661e-03 1.59676751e-03 2.79824363e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [1.68472529e-03 1.73670571e-04 2.22623581e-05 1.33686738e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [2.28047501e-04 0.00000000e+00 1.08165616e-03 6.95491342e-01]\n",
            " [1.37523413e-03 3.09948389e-01 1.51570238e-03 0.00000000e+00]\n",
            " [4.93380950e-02 7.00002539e-04 0.00000000e+00 2.78729755e-04]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 8.24916681e-01 1.38000746e-02]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 9.78512756e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}