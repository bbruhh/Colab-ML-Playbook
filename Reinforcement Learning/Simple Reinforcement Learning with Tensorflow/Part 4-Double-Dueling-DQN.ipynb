{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part 4-Double-Dueling-DQN.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "2UUDPrFMffH0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img height=\"60px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"20px\" vspace=\"5px\">\n",
        "\n",
        "# Simple Reinforcement Learning with Tensorflow Part 4: Deep Q-Networks andÂ Beyond\n",
        "\n",
        "In this iPython notebook I implement a Deep Q-Network using both Double DQN and Dueling DQN. The agent learn to solve a navigation task in a basic grid world. To learn more, read here: https://medium.com/p/8438a3e2b8df\n",
        "\n",
        "For more reinforcment learning tutorials, see:\n",
        "https://github.com/awjuliani/DeepRL-Agents"
      ]
    },
    {
      "metadata": {
        "id": "msurvnp-fkt0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/learning-stack/Colab-ML-Playbook/blob/master/Reinforcement%20Learning/Simple%20Reinforcement%20Learning%20with%20Tensorflow/Part%204-Double-Dueling-DQN.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/learning-stack/Colab-ML-Playbook/blob/master/Reinforcement%20Learning/Simple%20Reinforcement%20Learning%20with%20Tensorflow/Part%204-Double-Dueling-DQN.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "JmDFZny35T-V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea9f003c-7ce3-4034-9ffc-1081b12439b5"
      },
      "cell_type": "code",
      "source": [
        "#installing dependencies\n",
        "!apt-get -qq -y install libcusparse8.0 libnvrtc8.0 libnvtoolsext1 > /dev/null\n",
        "!ln -snf /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so.8.0 /usr/lib/x86_64-linux-gnu/libnvrtc-builtins.so\n",
        "!apt-get -qq -y install xvfb freeglut3-dev ffmpeg> /dev/null\n",
        "!pip -q install gym\n",
        "!pip -q install pyglet\n",
        "!pip -q install pyopengl\n",
        "!pip -q install pyvirtualdisplay"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting templates from packages: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uMeg2SRZffH2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "\n",
        "import gym\n",
        "import numpy as np\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.misc\n",
        "import os\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tv0vzm6qffH7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Load the game environment"
      ]
    },
    {
      "metadata": {
        "id": "kNSCTkT6ffH8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Feel free to adjust the size of the gridworld. Making it smaller provides an easier task for our DQN agent, while making the world larger increases the challenge."
      ]
    },
    {
      "metadata": {
        "id": "rgNQ724m7VYr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c38998b-97ad-47e5-96c3-703817321f84"
      },
      "cell_type": "code",
      "source": [
        "# Import custom library from my github\n",
        "\n",
        "import urllib.request\n",
        "\n",
        "def download(url):\n",
        "    filename = url.split('/')[-1]\n",
        "    print ('Downloading', filename)\n",
        "    f =  urllib.request.urlopen(url)\n",
        "    data = f.read()\n",
        "    f.close()\n",
        "    with open(filename, 'wb') as myfile:\n",
        "        myfile.write(data)\n",
        "\n",
        "# get .py file from repository\n",
        "download('https://raw.githubusercontent.com/learning-stack/Colab-ML-Playbook/master/Reinforcement%20Learning/Simple%20Reinforcement%20Learning%20with%20Tensorflow/gridworld.py')\n",
        "\n",
        "# verify the file if necessary\n",
        "# print(open('data_helpers.py').read())\n",
        "\n",
        "import gridworld\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading gridworld.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Ny0sHYosffH8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "01656d48-0bd2-47fe-87e4-96923f64cf1a"
      },
      "cell_type": "code",
      "source": [
        "from gridworld import gameEnv\n",
        "\n",
        "env = gameEnv(partial=False,size=5)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if issubdtype(ts, int):\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  elif issubdtype(type(size), float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPoAAAD7CAYAAABDsImYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlwr4P+MZBw+2DtadAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f78eda89160>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "8Pd9jSf7ffIC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Above is an example of a starting environment in our simple game. The agent controls the blue square, and can move up, down, left, or right. The goal is to move to the green square (for +1 reward) and avoid the red square (for -1 reward). The position of the three blocks is randomized every episode."
      ]
    },
    {
      "metadata": {
        "id": "4_y4-2ifffIC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Implementing the network itself"
      ]
    },
    {
      "metadata": {
        "id": "f9HR7yj3ffIE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Qnetwork():\n",
        "    def __init__(self,h_size):\n",
        "        #The network recieves a frame from the game, flattened into an array.\n",
        "        #It then resizes it and processes it through four convolutional layers.\n",
        "        self.scalarInput =  tf.placeholder(shape=[None,21168],dtype=tf.float32)\n",
        "        self.imageIn = tf.reshape(self.scalarInput,shape=[-1,84,84,3])\n",
        "        self.conv1 = slim.conv2d( \\\n",
        "            inputs=self.imageIn,num_outputs=32,kernel_size=[8,8],stride=[4,4],padding='VALID', biases_initializer=None)\n",
        "        self.conv2 = slim.conv2d( \\\n",
        "            inputs=self.conv1,num_outputs=64,kernel_size=[4,4],stride=[2,2],padding='VALID', biases_initializer=None)\n",
        "        self.conv3 = slim.conv2d( \\\n",
        "            inputs=self.conv2,num_outputs=64,kernel_size=[3,3],stride=[1,1],padding='VALID', biases_initializer=None)\n",
        "        self.conv4 = slim.conv2d( \\\n",
        "            inputs=self.conv3,num_outputs=h_size,kernel_size=[7,7],stride=[1,1],padding='VALID', biases_initializer=None)\n",
        "        \n",
        "        #We take the output from the final convolutional layer and split it into separate advantage and value streams.\n",
        "        self.streamAC,self.streamVC = tf.split(self.conv4,2,3)\n",
        "        self.streamA = slim.flatten(self.streamAC)\n",
        "        self.streamV = slim.flatten(self.streamVC)\n",
        "        xavier_init = tf.contrib.layers.xavier_initializer()\n",
        "        self.AW = tf.Variable(xavier_init([h_size//2,env.actions]))\n",
        "        self.VW = tf.Variable(xavier_init([h_size//2,1]))\n",
        "        self.Advantage = tf.matmul(self.streamA,self.AW)\n",
        "        self.Value = tf.matmul(self.streamV,self.VW)\n",
        "        \n",
        "        #Then combine them together to get our final Q-values.\n",
        "        self.Qout = self.Value + tf.subtract(self.Advantage,tf.reduce_mean(self.Advantage,axis=1,keep_dims=True))\n",
        "        self.predict = tf.argmax(self.Qout,1)\n",
        "        \n",
        "        #Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
        "        self.targetQ = tf.placeholder(shape=[None],dtype=tf.float32)\n",
        "        self.actions = tf.placeholder(shape=[None],dtype=tf.int32)\n",
        "        self.actions_onehot = tf.one_hot(self.actions,env.actions,dtype=tf.float32)\n",
        "        \n",
        "        self.Q = tf.reduce_sum(tf.multiply(self.Qout, self.actions_onehot), axis=1)\n",
        "        \n",
        "        self.td_error = tf.square(self.targetQ - self.Q)\n",
        "        self.loss = tf.reduce_mean(self.td_error)\n",
        "        self.trainer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
        "        self.updateModel = self.trainer.minimize(self.loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_pM_96dJffIH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Experience Replay"
      ]
    },
    {
      "metadata": {
        "id": "qdGCN-50ffII",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This class allows us to store experies and sample then randomly to train the network."
      ]
    },
    {
      "metadata": {
        "id": "gJSc8UsQffIK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class experience_buffer():\n",
        "    def __init__(self, buffer_size = 50000):\n",
        "        self.buffer = []\n",
        "        self.buffer_size = buffer_size\n",
        "    \n",
        "    def add(self,experience):\n",
        "        if len(self.buffer) + len(experience) >= self.buffer_size:\n",
        "            self.buffer[0:(len(experience)+len(self.buffer))-self.buffer_size] = []\n",
        "        self.buffer.extend(experience)\n",
        "            \n",
        "    def sample(self,size):\n",
        "        return np.reshape(np.array(random.sample(self.buffer,size)),[size,5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IIEm7Dc6ffIN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "This is a simple function to resize our game frames."
      ]
    },
    {
      "metadata": {
        "id": "Kyf12O3jffIN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def processState(states):\n",
        "    return np.reshape(states,[21168])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QL0Vy5btffIQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "These functions allow us to update the parameters of our target network with those of the primary network."
      ]
    },
    {
      "metadata": {
        "id": "gnpfXpxwffIR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def updateTargetGraph(tfVars,tau):\n",
        "    total_vars = len(tfVars)\n",
        "    op_holder = []\n",
        "    for idx,var in enumerate(tfVars[0:total_vars//2]):\n",
        "        op_holder.append(tfVars[idx+total_vars//2].assign((var.value()*tau) + ((1-tau)*tfVars[idx+total_vars//2].value())))\n",
        "    return op_holder\n",
        "\n",
        "def updateTarget(op_holder,sess):\n",
        "    for op in op_holder:\n",
        "        sess.run(op)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K2M4tZoTffIU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Training the network"
      ]
    },
    {
      "metadata": {
        "id": "3B610TB3ffIW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Setting all the training parameters"
      ]
    },
    {
      "metadata": {
        "id": "CTPZlsH0ffIZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 32 #How many experiences to use for each training step.\n",
        "update_freq = 4 #How often to perform a training step.\n",
        "y = .99 #Discount factor on the target Q-values\n",
        "startE = 1 #Starting chance of random action\n",
        "endE = 0.1 #Final chance of random action\n",
        "annealing_steps = 10000. #How many steps of training to reduce startE to endE.\n",
        "num_episodes = 10000 #How many episodes of game environment to train network with.\n",
        "pre_train_steps = 10000 #How many steps of random actions before training begins.\n",
        "max_epLength = 50 #The max allowed length of our episode.\n",
        "load_model = False #Whether to load a saved model.\n",
        "path = \"./dqn\" #The path to save our model to.\n",
        "h_size = 512 #The size of the final convolutional layer before splitting it into Advantage and Value streams.\n",
        "tau = 0.001 #Rate to update target network toward primary network"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NTdUv__SffIc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2886
        },
        "outputId": "6db1a6a5-44de-4608-b3b5-a238b95cfa94"
      },
      "cell_type": "code",
      "source": [
        "tf.reset_default_graph()\n",
        "mainQN = Qnetwork(h_size)\n",
        "targetQN = Qnetwork(h_size)\n",
        "\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "trainables = tf.trainable_variables()\n",
        "\n",
        "targetOps = updateTargetGraph(trainables,tau)\n",
        "\n",
        "myBuffer = experience_buffer()\n",
        "\n",
        "#Set the rate of random action decrease. \n",
        "e = startE\n",
        "stepDrop = (startE - endE)/annealing_steps\n",
        "\n",
        "#create lists to contain total rewards and steps per episode\n",
        "jList = []\n",
        "rList = []\n",
        "total_steps = 0\n",
        "\n",
        "#Make a path for our model to be saved in.\n",
        "if not os.path.exists(path):\n",
        "    os.makedirs(path)\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    if load_model == True:\n",
        "        print('Loading Model...')\n",
        "        ckpt = tf.train.get_checkpoint_state(path)\n",
        "        saver.restore(sess,ckpt.model_checkpoint_path)\n",
        "    for i in range(num_episodes):\n",
        "        episodeBuffer = experience_buffer()\n",
        "        #Reset environment and get first new observation\n",
        "        s = env.reset()\n",
        "        s = processState(s)\n",
        "        d = False\n",
        "        rAll = 0\n",
        "        j = 0\n",
        "        #The Q-Network\n",
        "        while j < max_epLength: #If the agent takes longer than 200 moves to reach either of the blocks, end the trial.\n",
        "            j+=1\n",
        "            #Choose an action by greedily (with e chance of random action) from the Q-network\n",
        "            if np.random.rand(1) < e or total_steps < pre_train_steps:\n",
        "                a = np.random.randint(0,4)\n",
        "            else:\n",
        "                a = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:[s]})[0]\n",
        "            s1,r,d = env.step(a)\n",
        "            s1 = processState(s1)\n",
        "            total_steps += 1\n",
        "            episodeBuffer.add(np.reshape(np.array([s,a,r,s1,d]),[1,5])) #Save the experience to our episode buffer.\n",
        "            \n",
        "            if total_steps > pre_train_steps:\n",
        "                if e > endE:\n",
        "                    e -= stepDrop\n",
        "                \n",
        "                if total_steps % (update_freq) == 0:\n",
        "                    trainBatch = myBuffer.sample(batch_size) #Get a random batch of experiences.\n",
        "                    #Below we perform the Double-DQN update to the target Q-values\n",
        "                    Q1 = sess.run(mainQN.predict,feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
        "                    Q2 = sess.run(targetQN.Qout,feed_dict={targetQN.scalarInput:np.vstack(trainBatch[:,3])})\n",
        "                    end_multiplier = -(trainBatch[:,4] - 1)\n",
        "                    doubleQ = Q2[range(batch_size),Q1]\n",
        "                    targetQ = trainBatch[:,2] + (y*doubleQ * end_multiplier)\n",
        "                    #Update the network with our target values.\n",
        "                    _ = sess.run(mainQN.updateModel, \\\n",
        "                        feed_dict={mainQN.scalarInput:np.vstack(trainBatch[:,0]),mainQN.targetQ:targetQ, mainQN.actions:trainBatch[:,1]})\n",
        "                    \n",
        "                    updateTarget(targetOps,sess) #Update the target network toward the primary network.\n",
        "            rAll += r\n",
        "            s = s1\n",
        "            \n",
        "            if d == True:\n",
        "\n",
        "                break\n",
        "        \n",
        "        myBuffer.add(episodeBuffer.buffer)\n",
        "        jList.append(j)\n",
        "        rList.append(rAll)\n",
        "        #Periodically save the model. \n",
        "        if i % 1000 == 0:\n",
        "            saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
        "            print(\"Saved Model\")\n",
        "        if len(rList) % 10 == 0:\n",
        "            print(total_steps,np.mean(rList[-10:]), e)\n",
        "    saver.save(sess,path+'/model-'+str(i)+'.ckpt')\n",
        "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-5-a690ebb74b4d>:23: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "keep_dims is deprecated, use keepdims instead\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:482: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if issubdtype(ts, int):\n",
            "/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py:485: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
            "  elif issubdtype(type(size), float):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Saved Model\n",
            "500 0.2 1\n",
            "1000 3.1 1\n",
            "1500 2.7 1\n",
            "2000 1.5 1\n",
            "2500 2.2 1\n",
            "3000 2.1 1\n",
            "3500 1.3 1\n",
            "4000 1.7 1\n",
            "4500 3.6 1\n",
            "5000 1.6 1\n",
            "5500 2.5 1\n",
            "6000 2.0 1\n",
            "6500 1.4 1\n",
            "7000 2.2 1\n",
            "7500 1.5 1\n",
            "8000 2.4 1\n",
            "8500 3.5 1\n",
            "9000 3.0 1\n",
            "9500 2.7 1\n",
            "10000 2.1 1\n",
            "10500 2.2 0.9549999999999828\n",
            "11000 2.7 0.9099999999999655\n",
            "11500 2.2 0.8649999999999483\n",
            "12000 2.6 0.819999999999931\n",
            "12500 2.7 0.7749999999999138\n",
            "13000 1.2 0.7299999999998965\n",
            "13500 0.6 0.6849999999998793\n",
            "14000 2.0 0.639999999999862\n",
            "14500 2.0 0.5949999999998448\n",
            "15000 2.5 0.5499999999998275\n",
            "15500 2.3 0.5049999999998103\n",
            "16000 1.4 0.4599999999998177\n",
            "16500 1.8 0.41499999999982823\n",
            "17000 2.1 0.36999999999983874\n",
            "17500 3.2 0.32499999999984924\n",
            "18000 1.9 0.27999999999985975\n",
            "18500 5.8 0.23499999999986562\n",
            "19000 3.4 0.18999999999986225\n",
            "19500 4.0 0.14499999999985888\n",
            "20000 3.5 0.09999999999985551\n",
            "20500 1.9 0.09999999999985551\n",
            "21000 5.9 0.09999999999985551\n",
            "21500 3.3 0.09999999999985551\n",
            "22000 5.0 0.09999999999985551\n",
            "22500 5.6 0.09999999999985551\n",
            "23000 2.9 0.09999999999985551\n",
            "23500 4.1 0.09999999999985551\n",
            "24000 3.6 0.09999999999985551\n",
            "24500 2.7 0.09999999999985551\n",
            "25000 8.1 0.09999999999985551\n",
            "25500 4.4 0.09999999999985551\n",
            "26000 5.7 0.09999999999985551\n",
            "26500 8.4 0.09999999999985551\n",
            "27000 6.6 0.09999999999985551\n",
            "27500 6.8 0.09999999999985551\n",
            "28000 9.6 0.09999999999985551\n",
            "28500 8.8 0.09999999999985551\n",
            "29000 10.5 0.09999999999985551\n",
            "29500 7.1 0.09999999999985551\n",
            "30000 6.8 0.09999999999985551\n",
            "30500 13.0 0.09999999999985551\n",
            "31000 8.6 0.09999999999985551\n",
            "31500 10.0 0.09999999999985551\n",
            "32000 11.5 0.09999999999985551\n",
            "32500 14.3 0.09999999999985551\n",
            "33000 17.1 0.09999999999985551\n",
            "33500 12.3 0.09999999999985551\n",
            "34000 11.9 0.09999999999985551\n",
            "34500 13.5 0.09999999999985551\n",
            "35000 13.3 0.09999999999985551\n",
            "35500 15.8 0.09999999999985551\n",
            "36000 13.4 0.09999999999985551\n",
            "36500 18.3 0.09999999999985551\n",
            "37000 13.4 0.09999999999985551\n",
            "37500 15.3 0.09999999999985551\n",
            "38000 15.2 0.09999999999985551\n",
            "38500 15.1 0.09999999999985551\n",
            "39000 19.8 0.09999999999985551\n",
            "39500 17.0 0.09999999999985551\n",
            "40000 19.2 0.09999999999985551\n",
            "40500 18.7 0.09999999999985551\n",
            "41000 20.7 0.09999999999985551\n",
            "41500 15.3 0.09999999999985551\n",
            "42000 18.5 0.09999999999985551\n",
            "42500 19.1 0.09999999999985551\n",
            "43000 15.3 0.09999999999985551\n",
            "43500 21.0 0.09999999999985551\n",
            "44000 21.1 0.09999999999985551\n",
            "44500 19.4 0.09999999999985551\n",
            "45000 21.7 0.09999999999985551\n",
            "45500 20.0 0.09999999999985551\n",
            "46000 17.5 0.09999999999985551\n",
            "46500 18.0 0.09999999999985551\n",
            "47000 19.1 0.09999999999985551\n",
            "47500 19.5 0.09999999999985551\n",
            "48000 18.9 0.09999999999985551\n",
            "48500 18.2 0.09999999999985551\n",
            "49000 18.4 0.09999999999985551\n",
            "49500 18.7 0.09999999999985551\n",
            "50000 21.3 0.09999999999985551\n",
            "Saved Model\n",
            "50500 19.7 0.09999999999985551\n",
            "51000 22.3 0.09999999999985551\n",
            "51500 22.0 0.09999999999985551\n",
            "52000 22.9 0.09999999999985551\n",
            "52500 19.7 0.09999999999985551\n",
            "53000 21.6 0.09999999999985551\n",
            "53500 21.1 0.09999999999985551\n",
            "54000 22.1 0.09999999999985551\n",
            "54500 22.5 0.09999999999985551\n",
            "55000 22.5 0.09999999999985551\n",
            "55500 22.2 0.09999999999985551\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-79f506f45d70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mmainQN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalarInput\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocessState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0mtotal_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gridworld.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mpenalty\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveChar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckGoal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrenderEnv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/gridworld.py\u001b[0m in \u001b[0;36mrenderEnv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhero\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m84\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'nearest'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lanczos'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bicubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cubic'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 490\u001b[0;31m     \u001b[0mimnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    491\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfromimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimnew\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    492\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample)\u001b[0m\n\u001b[1;32m   1539\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unknown resampling filter\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1541\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    780\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyaccess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpixel_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadonly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "6ZsqNuODffIg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Checking network learning"
      ]
    },
    {
      "metadata": {
        "id": "0qm3VPvQffIh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Mean reward over time"
      ]
    },
    {
      "metadata": {
        "id": "9k2LUcpnffIh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "24a93aa1-363d-4ce4-e4ad-0482ff00a000"
      },
      "cell_type": "code",
      "source": [
        "rMat = np.resize(np.array(rList),[len(rList)//100,100])\n",
        "rMean = np.average(rMat,1)\n",
        "plt.plot(rMean)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f77fa2f17b8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD7CAYAAACRxdTpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f78594deeb8>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}