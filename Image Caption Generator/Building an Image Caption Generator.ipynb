{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building an Image Caption Generator.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Uo-ehm8geSRx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img height=\"60px\" src=\"https://colab.research.google.com/img/colab_favicon.ico\" align=\"left\" hspace=\"20px\" vspace=\"5px\">\n",
        "\n",
        "# Building an Image Caption Generator"
      ]
    },
    {
      "metadata": {
        "id": "1Vvfx9mCevCf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "* References:\n",
        "\n",
        "[https://medium.freecodecamp.org/building-an-image-caption-generator-with-deep-learning-in-tensorflow-a142722e9b1f](https://medium.freecodecamp.org/building-an-image-caption-generator-with-deep-learning-in-tensorflow-a142722e9b1f)"
      ]
    },
    {
      "metadata": {
        "id": "TaASyCVleh_C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/learning-stack/Colab-ML-Playbook/blob/master/Image%20Caption%20Generator/Building%20an%20Image%20Caption%20Generator.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/learning-stack/Colab-ML-Playbook/blob/master/Image%20Caption%20Generator/Building%20an%20Image%20Caption%20Generator.ipynb\"><img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "metadata": {
        "id": "rqNU4oJKR7l4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e8ccad05-b2c2-4290-89c3-3d1c7d26e2cb"
      },
      "cell_type": "code",
      "source": [
        "!dir"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "42WF7IzYeSTR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mapxCPxUeSTa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "95481b9b-d148-4679-fa23-4722687815c4"
      },
      "cell_type": "code",
      "source": [
        "## download_model.py\n",
        "\n",
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "import requests\n",
        "\n",
        "model_dict = {\n",
        "    'show-and-tell-2M': '15Juh0gaYR0qv8GjRL1EvsigErdQXTmnt'\n",
        "}\n",
        "\n",
        "\n",
        "def download_and_extract_model(model_name, data_dir):\n",
        "    if not os.path.exists(data_dir):\n",
        "        os.makedirs(data_dir)\n",
        "\n",
        "    file_id = model_dict[model_name]\n",
        "    destination = os.path.join(data_dir, model_name + '.zip')\n",
        "    if not os.path.exists(destination):\n",
        "        print('Downloading model to %s' % destination)\n",
        "        download_file_from_google_drive(file_id, destination)\n",
        "        with zipfile.ZipFile(destination, 'r') as zip_ref:\n",
        "            print('Extracting model to %s' % data_dir)\n",
        "            zip_ref.extractall(data_dir)\n",
        "\n",
        "\n",
        "def download_file_from_google_drive(file_id, destination):\n",
        "    URL = \"https://drive.google.com/uc?export=download\"\n",
        "\n",
        "    session = requests.Session()\n",
        "\n",
        "    response = session.get(URL, params={'id': file_id}, stream=True)\n",
        "    token = get_confirm_token(response)\n",
        "    if token:\n",
        "        params = {'id': file_id, 'confirm': token}\n",
        "        response = session.get(URL, params=params, stream=True)\n",
        "\n",
        "    save_response_content(response, destination)\n",
        "\n",
        "\n",
        "def get_confirm_token(response):\n",
        "    for key, value in response.cookies.items():\n",
        "        if key.startswith('download_warning'):\n",
        "            return value\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def save_response_content(response, destination):\n",
        "    CHUNK_SIZE = 32768\n",
        "\n",
        "    with open(destination, \"wb\") as f:\n",
        "        for chunk in response.iter_content(CHUNK_SIZE):\n",
        "            if chunk:  # filter out keep-alive new chunks\n",
        "                f.write(chunk)\n",
        "\n",
        "\n",
        "\n",
        "download_and_extract_model('show-and-tell-2M', 'model')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading model to model/show-and-tell-2M.zip\n",
            "Extracting model to model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "btKBBDFchDdS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "171ee19d-416e-47f6-beb4-bc0c0c8e0818"
      },
      "cell_type": "code",
      "source": [
        "!dir model"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "show-and-tell-2M.zip  show-and-tell.pb\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZFzpdv2QhVMF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## model.py\n",
        "\n",
        "import logging\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class ShowAndTellModel(object):\n",
        "    def __init__(self, model_path):\n",
        "        self._model_path = model_path\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "        self._load_model(model_path)\n",
        "        self._sess = tf.Session(graph=tf.get_default_graph())\n",
        "\n",
        "    def _load_model(self, frozen_graph_path):\n",
        "        \"\"\"\n",
        "        Loads a frozen graph\n",
        "        :param frozen_graph_path: path to .pb graph\n",
        "        :type frozen_graph_path: str\n",
        "        \"\"\"\n",
        "\n",
        "        model_exp = os.path.expanduser(frozen_graph_path)\n",
        "        if os.path.isfile(model_exp):\n",
        "            self.logger.info('Loading model filename: %s' % model_exp)\n",
        "            with tf.gfile.FastGFile(model_exp, 'rb') as f:\n",
        "                graph_def = tf.GraphDef()\n",
        "                graph_def.ParseFromString(f.read())\n",
        "                tf.import_graph_def(graph_def, name='')\n",
        "        else:\n",
        "            raise RuntimeError(\"Missing model file at path: {}\".format(frozen_graph_path))\n",
        "\n",
        "    def feed_image(self, encoded_image):\n",
        "        initial_state = self._sess.run(fetches=\"lstm/initial_state:0\",\n",
        "                                       feed_dict={\"image_feed:0\": encoded_image})\n",
        "        return initial_state\n",
        "\n",
        "    def inference_step(self, input_feed, state_feed):\n",
        "        softmax_output, state_output = self._sess.run(\n",
        "            fetches=[\"softmax:0\", \"lstm/state:0\"],\n",
        "            feed_dict={\n",
        "                \"input_feed:0\": input_feed,\n",
        "                \"lstm/state_feed:0\": state_feed,\n",
        "            })\n",
        "        return softmax_output, state_output, None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DdwWHez8haJM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fcd0445-6a27-4a13-be09-deec6d3791f1"
      },
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "# Download the file from 'url' and save it locally under `filename`:  \n",
        "def download(url):\n",
        "    filename = url.split('/')[-1]\n",
        "    print ('Downloading', filename)\n",
        "    f =  urllib.request.urlopen(url)\n",
        "    data = f.read()\n",
        "    f.close()\n",
        "    with open(filename, 'wb') as myfile:\n",
        "        myfile.write(data)    \n",
        "\n",
        "# download vocab file\n",
        "download('https://raw.githubusercontent.com/learning-stack/Colab-ML-Playbook/master/Image%20Caption%20Generator/word_counts.txt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading word_counts.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJa1CmTBloYD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## vocabulary.py\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import logging\n",
        "import os\n",
        "\n",
        "\n",
        "class Vocabulary(object):\n",
        "    \"\"\"Vocabulary class for mapping words to ids\"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 vocab_file_path,\n",
        "                 start_token=\"<S>\",\n",
        "                 end_token=\"</S>\",\n",
        "                 unk_token=\"<UNK>\"):\n",
        "        \"\"\"Initializes the vocabulary.\n",
        "    \n",
        "        Args:\n",
        "          vocab_file_path: File containing the vocabulary, where the tokens are the first\n",
        "            whitespace-separated token on each line (other tokens are ignored) and\n",
        "            the token ids are the corresponding line numbers.\n",
        "          start_token: Special token denoting sequence start.\n",
        "          end_token: Special token denoting sequence end.\n",
        "          unk_token: Special token denoting unknown tokens.\n",
        "        \"\"\"\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "        if not os.path.exists(vocab_file_path):\n",
        "            self.logger.exception(\"Vocab file %s not found.\", vocab_file_path)\n",
        "            raise RuntimeError\n",
        "        self.logger.info(\"Initializing vocabulary from file: %s\", vocab_file_path)\n",
        "\n",
        "        with open(vocab_file_path, mode=\"r\") as f:\n",
        "            reverse_vocab = list(f.readlines())\n",
        "        reverse_vocab = [line.split()[0] for line in reverse_vocab]\n",
        "        assert start_token in reverse_vocab\n",
        "        assert end_token in reverse_vocab\n",
        "        if unk_token not in reverse_vocab:\n",
        "            reverse_vocab.append(unk_token)\n",
        "        vocab = dict([(x, y) for (y, x) in enumerate(reverse_vocab)])\n",
        "\n",
        "        self.logger.info(\"Created vocabulary with %d words\" % len(vocab))\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.reverse_vocab = reverse_vocab\n",
        "\n",
        "        self.start_id = vocab[start_token]\n",
        "        self.end_id = vocab[end_token]\n",
        "        self.unk_id = vocab[unk_token]\n",
        "\n",
        "    def token_to_id(self, token_id):\n",
        "        if token_id in self.vocab:\n",
        "            return self.vocab[token_id]\n",
        "        else:\n",
        "            return self.unk_id\n",
        "\n",
        "    def id_to_token(self, token_id):\n",
        "        if token_id >= len(self.reverse_vocab):\n",
        "            return self.reverse_vocab[self.unk_id]\n",
        "        else:\n",
        "            return self.reverse_vocab[token_id]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "chouJ24JlX2B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## caption_generator.py\n",
        "\n",
        "# Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Class for generating captions from an image-to-text model.\"\"\"\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import heapq\n",
        "import math\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class TopN(object):\n",
        "    \"\"\"Maintains the top n elements of an incrementally provided set.\"\"\"\n",
        "\n",
        "    def __init__(self, n):\n",
        "        self._n = n\n",
        "        self._data = []\n",
        "\n",
        "    def size(self):\n",
        "        assert self._data is not None\n",
        "        return len(self._data)\n",
        "\n",
        "    def push(self, x):\n",
        "        \"\"\"Pushes a new element.\"\"\"\n",
        "        assert self._data is not None\n",
        "        if len(self._data) < self._n:\n",
        "            heapq.heappush(self._data, x)\n",
        "        else:\n",
        "            heapq.heappushpop(self._data, x)\n",
        "\n",
        "    def extract(self, sort=False):\n",
        "        \"\"\"Extracts all elements from the TopN. This is a destructive operation.\n",
        "    \n",
        "        The only method that can be called immediately after extract() is reset().\n",
        "    \n",
        "        Args:\n",
        "          sort: Whether to return the elements in descending sorted order.\n",
        "    \n",
        "        Returns:\n",
        "          A list of data; the top n elements provided to the set.\n",
        "        \"\"\"\n",
        "        assert self._data is not None\n",
        "        data = self._data\n",
        "        self._data = None\n",
        "        if sort:\n",
        "            data.sort(reverse=True)\n",
        "        return data\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Returns the TopN to an empty state.\"\"\"\n",
        "        self._data = []\n",
        "\n",
        "\n",
        "class Caption(object):\n",
        "    \"\"\"Represents a complete or partial caption.\"\"\"\n",
        "\n",
        "    def __init__(self, sentence, state, logprob, score, metadata=None):\n",
        "        \"\"\"Initializes the Caption.\n",
        "        Args:\n",
        "          sentence: List of word ids in the caption.\n",
        "          state: Model state after generating the previous word.\n",
        "          logprob: Log-probability of the caption.\n",
        "          score: Score of the caption.\n",
        "          metadata: Optional metadata associated with the partial sentence. If not\n",
        "            None, a list of strings with the same length as 'sentence'.\n",
        "        \"\"\"\n",
        "        self.sentence = sentence\n",
        "        self.state = state\n",
        "        self.logprob = logprob\n",
        "        self.score = score\n",
        "        self.metadata = metadata\n",
        "\n",
        "    def __cmp__(self, other):\n",
        "        \"\"\"Compares Captions by score.\"\"\"\n",
        "        assert isinstance(other, Caption)\n",
        "        if self.score == other.score:\n",
        "            return 0\n",
        "        elif self.score < other.score:\n",
        "            return -1\n",
        "        else:\n",
        "            return 1\n",
        "\n",
        "    # For Python 3 compatibility (__cmp__ is deprecated).\n",
        "    def __lt__(self, other):\n",
        "        assert isinstance(other, Caption)\n",
        "        return self.score < other.score\n",
        "\n",
        "    # Also for Python 3 compatibility.\n",
        "    def __eq__(self, other):\n",
        "        assert isinstance(other, Caption)\n",
        "        return self.score == other.score\n",
        "\n",
        "\n",
        "class CaptionGenerator(object):\n",
        "    \"\"\"Class to generate captions from an image-to-text model.\n",
        "    This code is a modification of https://github.com/tensorflow/models/blob/master/research/im2txt/im2txt/inference_utils/caption_generator.py\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 model,\n",
        "                 vocab,\n",
        "                 beam_size=3,\n",
        "                 max_caption_length=20,\n",
        "                 length_normalization_factor=0.0):\n",
        "\n",
        "        self.vocab = vocab\n",
        "        self.model = model\n",
        "\n",
        "        self.beam_size = beam_size\n",
        "        self.max_caption_length = max_caption_length\n",
        "        self.length_normalization_factor = length_normalization_factor\n",
        "\n",
        "    def beam_search(self, encoded_image):\n",
        "        # Feed in the image to get the initial state.\n",
        "        partial_caption_beam = TopN(self.beam_size)\n",
        "        complete_captions = TopN(self.beam_size)\n",
        "        initial_state = self.model.feed_image(encoded_image)\n",
        "\n",
        "        initial_beam = Caption(\n",
        "            sentence=[self.vocab.start_id],\n",
        "            state=initial_state[0],\n",
        "            logprob=0.0,\n",
        "            score=0.0,\n",
        "            metadata=[\"\"])\n",
        "\n",
        "        partial_caption_beam.push(initial_beam)\n",
        "\n",
        "        # Run beam search.\n",
        "        for _ in range(self.max_caption_length - 1):\n",
        "            partial_captions_list = partial_caption_beam.extract()\n",
        "            partial_caption_beam.reset()\n",
        "            input_feed = np.array([c.sentence[-1] for c in partial_captions_list])\n",
        "            state_feed = np.array([c.state for c in partial_captions_list])\n",
        "\n",
        "            softmax, new_states, metadata = self.model.inference_step(input_feed,\n",
        "                                                                      state_feed)\n",
        "\n",
        "            for i, partial_caption in enumerate(partial_captions_list):\n",
        "                word_probabilities = softmax[i]\n",
        "                state = new_states[i]\n",
        "                # For this partial caption, get the beam_size most probable next words.\n",
        "                words_and_probs = list(enumerate(word_probabilities))\n",
        "                words_and_probs.sort(key=lambda x: -x[1])\n",
        "                words_and_probs = words_and_probs[0:self.beam_size]\n",
        "                # Each next word gives a new partial caption.\n",
        "                for w, p in words_and_probs:\n",
        "                    if p < 1e-12:\n",
        "                        continue  # Avoid log(0).\n",
        "                    sentence = partial_caption.sentence + [w]\n",
        "                    logprob = partial_caption.logprob + math.log(p)\n",
        "                    score = logprob\n",
        "                    if metadata:\n",
        "                        metadata_list = partial_caption.metadata + [metadata[i]]\n",
        "                    else:\n",
        "                        metadata_list = None\n",
        "                    if w == self.vocab.end_id:\n",
        "                        if self.length_normalization_factor > 0:\n",
        "                            score /= len(sentence) ** self.length_normalization_factor\n",
        "                        beam = Caption(sentence, state, logprob, score, metadata_list)\n",
        "                        complete_captions.push(beam)\n",
        "                    else:\n",
        "                        beam = Caption(sentence, state, logprob, score, metadata_list)\n",
        "                        partial_caption_beam.push(beam)\n",
        "            if partial_caption_beam.size() == 0:\n",
        "                # We have run out of partial candidates; happens when beam_size = 1.\n",
        "                break\n",
        "\n",
        "        # If we have no complete captions then fall back to the partial captions.\n",
        "        # But never output a mixture of complete and partial captions because a\n",
        "        # partial caption could have a higher score than all the complete captions.\n",
        "        if complete_captions.size() == 0:\n",
        "            complete_captions = partial_caption_beam\n",
        "\n",
        "        return complete_captions.extract(sort=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1Rb1FoLoYPe7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "47868f80-d528-45b1-ccfd-2829d0fc8186"
      },
      "cell_type": "code",
      "source": [
        "# Download input file\n",
        "download('https://github.com/learning-stack/Colab-ML-Playbook/raw/master/Image%20Caption%20Generator/trading_floor.jpg')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading trading_floor.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AgAMyLBdl0uk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## inference.py\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import logging\n",
        "import math\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "FLAGS = tf.flags.FLAGS\n",
        "\n",
        "tf.flags.DEFINE_string(\"model_path\", \"model/show-and-tell.pb\", \"Model graph def path\")\n",
        "tf.flags.DEFINE_string(\"vocab_file\", \"word_counts.txt\", \"Text file containing the vocabulary.\")\n",
        "tf.flags.DEFINE_string(\"input_files\", \"trading_floor.jpg\",\n",
        "                       \"File pattern or comma-separated list of file patterns \"\n",
        "                       \"of image files.\")\n",
        "\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xB0t688MmM9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "31108d6c-90aa-449d-ea2e-390ddaa953c5"
      },
      "cell_type": "code",
      "source": [
        "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
        "print(FLAGS.model_path)\n",
        "print(FLAGS.vocab_file)\n",
        "print(FLAGS.input_files)\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model/show-and-tell.pb\n",
            "word_counts.txt\n",
            "trading_floor.jpg\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "wY6ZW71KUEUl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23174af6-04c6-4371-8be3-09e9bc533c61"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = ShowAndTellModel(FLAGS.model_path)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Loading model filename: model/show-and-tell.pb\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "tNG-JAI8ZkVs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ad8bb93f-68b8-4dd7-f6d2-b4fa294e0b32"
      },
      "cell_type": "code",
      "source": [
        "vocab = Vocabulary(FLAGS.vocab_file)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:__main__:Initializing vocabulary from file: word_counts.txt\n",
            "INFO:__main__:Created vocabulary with 11519 words\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "jjRM3IBiZncd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generator = CaptionGenerator(model, vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8h_dp6b7ZquN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "5fbbac76-3f08-4ea8-f292-46bb39d49082"
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-f365b12874cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcaptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeam_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Captions for image %s:\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filenames' is not defined"
          ]
        }
      ]
    }
  ]
}